# Playwright AI Agents - Test Automation

Projekt automatyzacji testÃ³w wykorzystujÄ…cy:

- **Playwright** - framework do testÃ³w E2E
- **Playwright BDD** - wsparcie dla Gherkin/Cucumber
- **Ollama** - lokalne uruchamianie LLM
- **OpenAI SDK** - komunikacja z lokalnym LLM

## ğŸ“‹ Spis treÅ›ci

- [ğŸš€ Quick Start](#-quick-start)
  - [1. Instalacja zaleÅ¼noÅ›ci](#1-instalacja-zaleÅ¼noÅ›ci)
  - [2. Konfiguracja Ollama](#2-konfiguracja-ollama)
  - [3. Instalacja modelu](#3-instalacja-modelu)
  - [4. Konfiguracja parametrÃ³w modelu](#4-konfiguracja-parametrÃ³w-modelu)
  - [5. Aktualizacja .env](#5-aktualizacja-env)
  - [6. Uruchomienie testÃ³w](#6-uruchomienie-testÃ³w)
- [ğŸ“ Struktura Projektu](#-struktura-projektu)
- [ğŸ§ª PrzykÅ‚adowy Test](#-przykÅ‚adowy-test)
- [ğŸ¤– AIHelper API](#-aihelper-api)
- [âš™ï¸ Konfiguracja](#ï¸-konfiguracja)
  - [Zmienne Å›rodowiskowe (.env)](#zmienne-Å›rodowiskowe-env)
  - [Parametry modelu](#parametry-modelu)
- [ğŸ› Debugging](#-debugging)
  - [Logi AI](#logi-ai)
  - [Uruchomienie w trybie debug](#uruchomienie-w-trybie-debug)
  - [Uruchomienie z widocznÄ… przeglÄ…darkÄ…](#uruchomienie-z-widocznÄ…-przeglÄ…darkÄ…)
- [ğŸ“Š Raport testÃ³w](#-raport-testÃ³w)
- [ğŸ”§ Optymalizacja wydajnoÅ›ci](#-optymalizacja-wydajnoÅ›ci)
- [ğŸ“š Dodatkowe informacje](#-dodatkowe-informacje)
- [ğŸª Git Hooks](#-git-hooks)
- [ğŸ”„ CI/CD](#-cicd)
  - [Szybki start z CI](#szybki-start-z-ci)
- [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting)

---

## ğŸš€ Quick Start

### 1. Instalacja zaleÅ¼noÅ›ci

```bash
npm install
```

### 2. Konfiguracja Ollama

Przed uruchomieniem testÃ³w, sprawdÅº konfiguracjÄ™ Ollama:

```bash
npm run diagnose
```

Skrypt diagnostyczny sprawdzi:

- Czy Ollama jest uruchomiona
- DostÄ™pne modele
- Zasoby systemowe
- Wygeneruje optymalnÄ… konfiguracjÄ™ modelu

### 3. Instalacja modelu

Zainstaluj zalecany model (np. llama3.1:8b):

```bash
ollama pull llama3.1:8b
```

### 4. Konfiguracja parametrÃ³w modelu

Skrypt diagnostyczny utworzy plik `Modelfile`. UtwÃ³rz zoptymalizowany model:

```bash
ollama create playwright-model -f Modelfile
```

### 5. Aktualizacja .env

Zaktualizuj plik `.env` z nazwÄ… utworzonego modelu:

```env
OLLAMA_MODEL=playwright-model
```

### 6. Uruchomienie testÃ³w

```bash
npm test
```

## ğŸ“ Struktura Projektu

```
playwright-agents/
â”œâ”€â”€ features/           # Pliki .feature (Gherkin)
â”‚   â””â”€â”€ shopping.feature
â”œâ”€â”€ steps/              # Implementacje krokÃ³w BDD
â”‚   â””â”€â”€ shopping.steps.ts
â”œâ”€â”€ utils/              # Pomocnicze utility
â”‚   â””â”€â”€ ai-helper.ts    # Wrapper dla Ollama AI
â”œâ”€â”€ scripts/            # Skrypty pomocnicze
â”‚   â”œâ”€â”€ diagnose-ollama.py
â”‚   â””â”€â”€ diagnose-ollama.sh
â”œâ”€â”€ logs/               # Logi promptÃ³w AI (auto-generated)
â”œâ”€â”€ playwright.config.ts
â”œâ”€â”€ .env
â””â”€â”€ package.json
```

## ğŸ§ª PrzykÅ‚adowy Test

```gherkin
Feature: Shopping Cart
  Scenario: Add product to cart
    Given I am on the products page
    When  I click on "Add to cart" button for the first product
    Then  I should see the cart counter increase
    And   the product should appear in the cart
```

## ğŸ¤– AIHelper API

Klasa `AIHelper` dostarcza metody do interakcji z UI uÅ¼ywajÄ…c lokalnego LLM:

```typescript
const aiHelper = new AIHelper(page);

// Kliknij element
await aiHelper.click('login button');

// WypeÅ‚nij pole
await aiHelper.fill('username field', 'testuser');

// Zweryfikuj obecnoÅ›Ä‡ elementu
const isVisible = await aiHelper.verify('success message');
```

Wszystkie interakcje sÄ… logowane do `logs/ai-prompts-*.log` dla debugowania.

## âš™ï¸ Konfiguracja

### Zmienne Å›rodowiskowe (.env)

```env
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama
OLLAMA_MODEL=llama3.1:8b

# Model Parameters
OLLAMA_TEMPERATURE=0         # Deterministyczne odpowiedzi
OLLAMA_NUM_CTX=8192         # WiÄ™kszy kontekst dla DOM

# Playwright Configuration
PLAYWRIGHT_TIMEOUT=90000     # 90s timeout
PLAYWRIGHT_EXPECT_TIMEOUT=30000
```

### Parametry modelu

- **temperature=0**: Eliminuje losowoÅ›Ä‡, zapewnia deterministyczne selektory
- **num_ctx=8192**: WiÄ™kszy kontekst aby pomieÅ›ciÄ‡ strukturÄ™ DOM strony
- **top_k=10**: Ogranicza wybÃ³r tokenÃ³w do najbardziej prawdopodobnych

## ğŸ› Debugging

### Logi AI

Wszystkie prompty wysyÅ‚ane do AI sÄ… logowane w katalogu `logs/`:

```bash
cat logs/ai-prompts-*.log
```

### Uruchomienie w trybie debug

```bash
npm run test:debug
```

### Uruchomienie z widocznÄ… przeglÄ…darkÄ…

```bash
npm run test:headed
```

## ğŸ“Š Raport testÃ³w

Po wykonaniu testÃ³w, wygeneruj raport HTML:

```bash
npm run report
```

## ğŸ”§ Optymalizacja wydajnoÅ›ci

1. **WybÃ³r modelu**: Dla 8GB+ RAM uÅ¼yj `llama3.1:8b`, dla mniejszych zasobÃ³w `llama3.2:3b` lub `phi3:mini`
2. **Timeouty**: Lokalne LLM sÄ… wolniejsze - timeouty sÄ… zwiÄ™kszone do 60-90s
3. **Kontekst**: HTML jest uproszczany przed wysÅ‚aniem do LLM aby zmniejszyÄ‡ liczbÄ™ tokenÃ³w
4. **RÃ³wnolegÅ‚oÅ›Ä‡**: Testy uruchamiane sekwencyjnie (`workers: 1`) aby nie przeciÄ…Å¼yÄ‡ GPU/CPU

## ğŸ“š Dodatkowe informacje

- [Playwright Documentation](https://playwright.dev)
- [Playwright BDD](https://github.com/vitalets/playwright-bdd)
- [Ollama Documentation](https://ollama.ai/docs)
- [OpenAI SDK](https://github.com/openai/openai-node)
- **[GitHub Actions z Ollama](GITHUB_ACTIONS.md)** - Przewodnik po uruchamianiu testÃ³w w CI/CD
- **[Husky + Git Hooks](HUSKY.md)** - Automatyczna weryfikacja kodu przed commitem

## ğŸª Git Hooks

Projekt uÅ¼ywa **Husky** do automatycznej weryfikacji kodu:

- **Pre-commit**: ESLint + Prettier sprawdzajÄ… i formatujÄ… kod
- **Commit-msg**: Wymusza Conventional Commits format

```bash
# Poprawny format commit message:
git commit -m "feat(tests): add new shopping test"
git commit -m "fix(ai-helper): improve selector fallback"
git commit -m "docs(readme): update installation guide"
```

Zobacz szczegÃ³Å‚y: **[HUSKY.md](HUSKY.md)**

## ğŸ”„ CI/CD

Projekt zawiera 2 workflows z automatycznym deploymentem raportÃ³w do GitHub Pages:

- **Playwright - Self-Hosted** - `.github/workflows/playwright-self-hosted.yml`
  - Uruchamia siÄ™ przy push do `main`
  - UÅ¼ywa modelu `llama3.2-vision:latest`
  - Automatyczny deployment raportu
  - ~115s execution time
- **Playwright - GitHub-Hosted** - `.github/workflows/playwright-github-hosted.yml`
  - Uruchamia siÄ™ przy push/PR
  - UÅ¼ywa Groq API `llama-3.1-8b-instant` (ultra-fast)
  - Automatyczny deployment raportu
  - ~37s execution time

**ğŸ“Š Raporty testÃ³w dostÄ™pne na GitHub Pages:**

Wszystkie raporty sÄ… automatycznie publikowane na:

- **Strona gÅ‚Ã³wna:** https://leonardust.github.io/playwright-agents/
- **Self-hosted latest:** https://leonardust.github.io/playwright-agents/self-hosted/latest/
- **GitHub-hosted latest:** https://leonardust.github.io/playwright-agents/github-hosted/latest/

Strona gÅ‚Ã³wna zawiera:

- Przyciski do najnowszych raportÃ³w
- HistoriÄ™ ostatnich 20 raportÃ³w dla kaÅ¼dego typu
- Automatycznie aktualizowane timestamps

Zobacz szczegÃ³Å‚owy przewodnik: **[GITHUB_ACTIONS.md](GITHUB_ACTIONS.md)**

### Szybki start z CI:

```bash
# Opcja 1: Self-hosted runner (zalecane)
# 1. Zainstaluj runner na swoim komputerze (jako serwis Windows)
# 2. Uruchom Ollama lokalnie
# 3. Push do repo - testy uruchomiÄ… siÄ™ automatycznie
# 4. Raport pojawi siÄ™ w workflow summary i na GitHub Pages

# Opcja 2: GitHub-hosted runner
# 1. Workflow automatycznie instaluje Ollama i phi3:mini
# 2. Uruchom tylko smoke tests (@smoke tag)
# 3. Raport automatycznie na GitHub Pages
```

## ğŸ› ï¸ Troubleshooting

### Ollama nie odpowiada

```bash
# SprawdÅº czy Ollama dziaÅ‚a
curl http://localhost:11434/api/tags

# JeÅ›li nie, uruchom:
ollama serve
```

### Testy timeout'ujÄ…

ZwiÄ™ksz timeouty w `.env`:

```env
PLAYWRIGHT_TIMEOUT=120000
PLAYWRIGHT_EXPECT_TIMEOUT=45000
```

### AI zwraca niepoprawne selektory

1. SprawdÅº logi: `logs/ai-prompts-*.log`
2. Upewnij siÄ™ Å¼e `temperature=0`
3. RozwaÅ¼ uÅ¼ycie wiÄ™kszego modelu
